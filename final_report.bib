@article{keras,
  title="Keras",
  author="Chollet, Fran\c{c}ois and others",
  year="2015",
  note={https://keras.io}
}
@article{keras_bert,
    author = {CyberZHG},
    title = {keras-bert},
    year = 2019,
    version = {v0.60.0},
    publisher = {GitHub},
    note = {https://github.com/CyberZHG/keras-bert},
}
@inproceedings{niven-kao-2019-probing,
    title = "Probing Neural Network Comprehension of Natural Language Arguments",
    author = "Niven, Timothy  and
      Kao, Hung-Yu",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1459",
    doi = "10.18653/v1/P19-1459",
    pages = "4658--4664",
    abstract = "We are surprised to find that BERT{'}s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.",
}
@article{wordcloud,
    author = {amueller},
    title = {wordcloud},
    year = 2019,
    version = {v1.6.0},
    publisher = {GitHub},
    note = {https://github.com/amueller/word\_cloud},
}
@article{seaborn,
  author       = {Michael Waskom and
                  Olga Botvinnik and
                  Drew O'Kane and
                  Paul Hobson and
                  Joel Ostblom and
                  Saulius Lukauskas and
                  David C Gemperline and
                  Tom Augspurger and
                  Yaroslav Halchenko and
                  John B. Cole and
                  Jordi Warmenhoven and
                  Julian de Ruiter and
                  Cameron Pye and
                  Stephan Hoyer and
                  Jake Vanderplas and
                  Santi Villalba and
                  Gero Kunter and
                  Eric Quintero and
                  Pete Bachant and
                  Marcel Martin and
                  Kyle Meyer and
                  Alistair Miles and
                  Yoav Ram and
                  Thomas Brunner and
                  Tal Yarkoni and
                  Mike Lee Williams and
                  Constantine Evans and
                  Clark Fitzgerald and
                  Brian and
                  Adel Qalieh},
  title        = {seaborn},
  year         = 2018,
  note = {https://doi.org/10.5281/zenodo.1313201},
}
@article{bag_of_words, 
  title={Distributional Structure}, 
  DOI={10.1007/978-94-009-8467-7_1}, 
  journal={Papers on Syntax}, 
  author={Harris, Zellig S.}, 
  year={1981}, 
  pages={3â€“22}
}
@article{cnn,
Author = {Yoon Kim},
Title = {Convolutional Neural Networks for Sentence Classification},
Year = {2014},
Journal = {arXiv},
note = {Retrieved electronically from https://arxiv.org/pdf/1408.5882.pdf},
Eprint = {arXiv:1408.5882},
}
@article{data,
Author = {Zynicide},
Title = {Wine Reviews},
Year = {2017},
Journal = {Kaggle},
note = {Retrieved electronically from https://www.kaggle.com/zynicide/wine-reviews},
}
@misc{wine_scoring, 
title={Wine Spectator's 100-Point Scale}, 
url={https://www.winespectator.com/articles/scoring-scale}, 
journal={Wine Spectator}, 
author={Frank, Mitch and Marsteller, Daniel}, 
year={2019}, 
month={Nov}
}
@inproceedings{clever_hans,
    title = "Probing Neural Network Comprehension of Natural Language Arguments",
    author = "Niven, Timothy  and
      Kao, Hung-Yu",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1459",
    doi = "10.18653/v1/P19-1459",
    pages = "4658--4664",
    abstract = "We are surprised to find that BERT{'}s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.",
}
@incollection{word2vec,
title = {Distributed Representations of Words and Phrases and their Compositionality},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {3111--3119},
year = {2013},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf}
}
@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}
@article{sklearn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@inproceedings{gensim,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}